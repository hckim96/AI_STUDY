{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('dataStudy': conda)",
   "display_name": "Python 3.8.5 64-bit ('dataStudy': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a22da94b6d0eb1bb9e13ff23c6dec5d5d0682dd7591db237e737d29eb0bbf2ae"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# CHAPTER 01. 파이썬 기반의 머신러닝과 생태계 이해\n",
    "\n",
    "## 01. 머신러닝의 개념\n",
    "\n",
    "데이터를 기반으로 패턴을 학습하고 결과를 예측하는 알고리즘 기법\n",
    "\n",
    "- 머신러닝을 활용하여 해결할 수 있는 문제점\n",
    "    - 변화하는 외부 조건에 맞춰서 수시로 코드를 변경해줘야 함.\n",
    "    - 데이터를 관통하는 일정한 패턴, 조건을 찾기 어려움.\n",
    "\n",
    "- 학습법\n",
    "    1. 지도학습\n",
    "        - 정답이 있는 데이터를 학습. (데이터 라벨링)\n",
    "        - ex. 이 사진은 고양이 사진, 이 사진은 강아지 사진\n",
    "        - 라벨링을 사람이 해야되서 시간과 비용이 많이 든다.\n",
    "    2. 비지도학습\n",
    "        - 라벨링을 하지 않은 사진들을 군집화\n",
    "        - ex. 고양이 사진, 강아지 사진을, 병아리 사진을 다리의 개수를 feature 로 찾아 다리 2개, 다리 4개인 동물의 사진들로 군집화\n",
    "        - 지도학습에서의 feature 를 찾기위한 전처리과정으로 사용하기도 한다.\n",
    "    3. 강화학습\n",
    "        - 어떤 행동을 했을 때의 reward를 지정하여 학습. reward 가 최대인 행동을 하도록 한다.\n",
    "        \n",
    "## 03. 넘파이\n",
    "\n",
    "데이터 핸들링에서 판다스보다 불편하지만 많은 알고리즘이 넘파이 기반으로 작성되어 있어 다른 데이터 핸들링 패키지(ex. pandas) 를 이해하는 기반을 다지기 좋다.\n",
    "\n",
    "### ndarray\n",
    "\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'numpy.ndarray'>\n(3,)\n<class 'numpy.ndarray'>\n(2, 1)\n<class 'numpy.ndarray'>\n(3, 2, 1)\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "arr = np.array([1, 2, 3])\n",
    "print(type(arr))\n",
    "print(arr.shape)\n",
    "\n",
    "arr = np.array([[1],[2]])\n",
    "print(type(arr))\n",
    "print(arr.shape)\n",
    "\n",
    "arr = np.array([[[1], [2]], [[3], [4]], [[5],[6]]])\n",
    "print(type(arr))\n",
    "print(arr.shape)\n",
    "# shape : (x, y)  --> 원소 개수 y 개인 배열이 x 개 있는 배열."
   ]
  },
  {
   "source": [
    "ndarray 안의 데이터 타입은 한 종류이다.\n",
    "\n",
    "다른 타입의 데이터로 ndarray 를 만들면 크기가 가장 큰 데이터 타입으로 캐스팅된다.\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1.  2.  3.2] float64\n['1' '2'] <U1\n['1' 'abdc'] <U4\n"
    }
   ],
   "source": [
    "arr = np.array([1, 2, 3.2])\n",
    "print(arr, arr.dtype)\n",
    "\n",
    "arr = np.array(['1','2'])\n",
    "print(arr, arr.dtype)\n",
    "\n",
    "arr = np.array(['1', 'abdc'])\n",
    "print(arr, arr.dtype)"
   ]
  },
  {
   "source": [
    "asypte() method로 ndarray 내 데이터 타입을 변환 할 수 있다.\n",
    "\n",
    "기존 데이터 타입보다 작은 데이터 타입으로 변환할 경우 데이터 손실이 일어날 수 있다. (ex. float -> int :: 소수점 이하 사라짐)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[1.5 2.3] float64\n[1 2] int32\n[1. 2.] float64\n"
    }
   ],
   "source": [
    "arr = np.array([1.5, 2.3])\n",
    "print(arr, arr.dtype)\n",
    "\n",
    "arr = arr.astype('int32')\n",
    "print(arr, arr.dtype)\n",
    "\n",
    "arr = arr.astype('float64')\n",
    "print(arr, arr.dtype)\n",
    "# .5 .3 사라짐"
   ]
  },
  {
   "source": [
    "method arange, zeros, ones 로 초기화 가능\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 1 2 3 4 5 6 7 8 9] int64\n[[0. 0.]\n [0. 0.]\n [0. 0.]] float64\n[[1. 1.]\n [1. 1.]\n [1. 1.]] float64\n"
    }
   ],
   "source": [
    "arr = np.arange(10)\n",
    "# 파라미터: 범위 start, stop 지정 가능\n",
    "print(arr, arr.dtype)\n",
    "\n",
    "arr = np.zeros((3, 2)) \n",
    "# 파라미터: 만들 ndarray 의 shape 과 dtype(default = float64)\n",
    "print(arr, arr.dtype)\n",
    "\n",
    "arr = np.ones((3,2))\n",
    "# 파라미터: 만들 ndarray 의 shape, dtype (default = float64)\n",
    "print(arr, arr.dtype)\n",
    "\n"
   ]
  },
  {
   "source": [
    "reshape() method 로 ndarray shape 바꾸기 가능 (변경 불가능 하면 오류)\n",
    "\n",
    "-1 하면 변환 가능한 모양으로 찾아서 변환해준다.\n",
    "\n",
    "tolist() 를 사용하면 ndarray 를 list 로 변환 해주는데 \n",
    "\n",
    "print 함수가 list 출력하는게 사람이 보기 편하다. (ndarray는 행 마다 라인피드)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "[0 1 2 3 4 5 6 7 8 9]\n[[0 1 2 3 4]\n [5 6 7 8 9]]\n[[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n[[0, 1, 2, 3, 4], [5, 6, 7, 8, 9]]\n[[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n[[0, 1], [2, 3], [4, 5], [6, 7], [8, 9]]\n"
    }
   ],
   "source": [
    "arr = np.arange(10)\n",
    "print(arr)\n",
    "\n",
    "print(arr.reshape(2,5))\n",
    "print(arr.reshape(2,5).tolist())\n",
    "print(arr.reshape(-1,5).tolist())\n",
    "\n",
    "print(arr.reshape(5,2).tolist())\n",
    "print(arr.reshape(5,-1).tolist())"
   ]
  },
  {
   "source": [
    "### 넘파이의 ndarray의 데이터 세트 선택하기 - 인덱싱(Indexing)\n",
    "\n",
    "- []연산자로 ndarray 에서 random access 가능 (read, write)\n",
    "- 2차원 ndarray의 경우 \\[row, col\\] 으로 접근 가능 (n 차원도 비슷)\n",
    "- \\[start: stop\\] 으로 start ~ stop - 1 인덱스의 데이터를 슬라이싱 가능(새로운 ndarray 결과로 나옴)\n",
    "- fancy indexing : index 집합으로 좀 더 원하는 구역을 세분화해서 추출 가능\n",
    "- boolean indexing : \\[조건식\\] -> 조건식 만족하는 데이터 추출 가능\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 행렬의 정렬 - sort()와 argsort()\n",
    "\n",
    "- np.sort(원본) -> 원본 그대로 두고 정렬 결과 행렬 새롭게 반환\n",
    "- 원본.sort() -> 원본 행렬을 정렬함.(sort() 호출한 행렬 직접적으로 바꿈)\n",
    "- sort() - 기본적으로 오름차순(내림차순으로 하려면 sort()[::-1])\n",
    "- sort(arr, axis) - axis parameter 로 정렬방향 정하기 가능\n",
    "- np.argsort() - 정렬했을 때의 인덱스를 나타냄\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 선형대수 연산 - 행렬 내적과 전치 행렬 구하기\n",
    "\n",
    "- np.dot() - 내적\n",
    "- np.transepose() - 전치행렬 (행, 열 바꾼 행렬)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## 04. 데이터 핸들링 - 판다스\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   PassengerId  Survived  Pclass  \\\n0            1         0       3   \n1            2         1       1   \n2            3         1       3   \n\n                                                Name     Sex   Age  SibSp  \\\n0                            Braund, Mr. Owen Harris    male  22.0      1   \n1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n2                             Heikkinen, Miss. Laina  female  26.0      0   \n\n   Parch            Ticket     Fare Cabin Embarked  \n0      0         A/5 21171   7.2500   NaN        S  \n1      0          PC 17599  71.2833   C85        C  \n2      0  STON/O2. 3101282   7.9250   NaN        S  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Name</th>\n      <th>Sex</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Ticket</th>\n      <th>Fare</th>\n      <th>Cabin</th>\n      <th>Embarked</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n      <td>3</td>\n      <td>Braund, Mr. Owen Harris</td>\n      <td>male</td>\n      <td>22.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>A/5 21171</td>\n      <td>7.2500</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n      <td>1</td>\n      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n      <td>female</td>\n      <td>38.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>PC 17599</td>\n      <td>71.2833</td>\n      <td>C85</td>\n      <td>C</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n      <td>3</td>\n      <td>Heikkinen, Miss. Laina</td>\n      <td>female</td>\n      <td>26.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>STON/O2. 3101282</td>\n      <td>7.9250</td>\n      <td>NaN</td>\n      <td>S</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 29
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic_df = pd.read_csv(\"../data/titanic_train.csv\")\n",
    "titanic_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(891, 12)"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "titanic_df.shape #891 rows, 12 cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 891 entries, 0 to 890\nData columns (total 12 columns):\n #   Column       Non-Null Count  Dtype  \n---  ------       --------------  -----  \n 0   PassengerId  891 non-null    int64  \n 1   Survived     891 non-null    int64  \n 2   Pclass       891 non-null    int64  \n 3   Name         891 non-null    object \n 4   Sex          891 non-null    object \n 5   Age          714 non-null    float64\n 6   SibSp        891 non-null    int64  \n 7   Parch        891 non-null    int64  \n 8   Ticket       891 non-null    object \n 9   Fare         891 non-null    float64\n 10  Cabin        204 non-null    object \n 11  Embarked     889 non-null    object \ndtypes: float64(2), int64(5), object(5)\nmemory usage: 83.7+ KB\n"
    }
   ],
   "source": [
    "titanic_df.info() # 칼럼, non null, 데이터 타입"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "       PassengerId    Survived      Pclass         Age       SibSp  \\\ncount   891.000000  891.000000  891.000000  714.000000  891.000000   \nmean    446.000000    0.383838    2.308642   29.699118    0.523008   \nstd     257.353842    0.486592    0.836071   14.526497    1.102743   \nmin       1.000000    0.000000    1.000000    0.420000    0.000000   \n25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n75%     668.500000    1.000000    3.000000   38.000000    1.000000   \nmax     891.000000    1.000000    3.000000   80.000000    8.000000   \n\n            Parch        Fare  \ncount  891.000000  891.000000  \nmean     0.381594   32.204208  \nstd      0.806057   49.693429  \nmin      0.000000    0.000000  \n25%      0.000000    7.910400  \n50%      0.000000   14.454200  \n75%      0.000000   31.000000  \nmax      6.000000  512.329200  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PassengerId</th>\n      <th>Survived</th>\n      <th>Pclass</th>\n      <th>Age</th>\n      <th>SibSp</th>\n      <th>Parch</th>\n      <th>Fare</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>714.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n      <td>891.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>446.000000</td>\n      <td>0.383838</td>\n      <td>2.308642</td>\n      <td>29.699118</td>\n      <td>0.523008</td>\n      <td>0.381594</td>\n      <td>32.204208</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>257.353842</td>\n      <td>0.486592</td>\n      <td>0.836071</td>\n      <td>14.526497</td>\n      <td>1.102743</td>\n      <td>0.806057</td>\n      <td>49.693429</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>1.000000</td>\n      <td>0.420000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>223.500000</td>\n      <td>0.000000</td>\n      <td>2.000000</td>\n      <td>20.125000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>7.910400</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>446.000000</td>\n      <td>0.000000</td>\n      <td>3.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>14.454200</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>668.500000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>38.000000</td>\n      <td>1.000000</td>\n      <td>0.000000</td>\n      <td>31.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>891.000000</td>\n      <td>1.000000</td>\n      <td>3.000000</td>\n      <td>80.000000</td>\n      <td>8.000000</td>\n      <td>6.000000</td>\n      <td>512.329200</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "source": [
    "titanic_df.describe() # 데이터 분포"
   ]
  },
  {
   "source": [
    "- value_counts() - 데이터 값 개수 (series)\n",
    "- \\[col\\] - 해당 column  series\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### DataFrame과 리스트, 딕셔너리, 넘파이 ndarray 상호 변환\n",
    "\n",
    "- pd.DataFrame(list or ndarray, col_names) - list 와 ndarray 로 dataframe 만들기 가능\n",
    "- pd.DataFrame(dict) - dict의 key = col_name, value = data 로 매핑해서 dataframe 만듦\n",
    "- df.values - ndarray 리턴\n",
    "- 위에서 얻은 ndarray 의 tolist() 메서드로 list 로 변환 가능\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### DataFrame의 칼럼 데이터 세트 생성과 수정\n",
    "\n",
    "- [] 로 시리즈 접근 -> 시리즈에 연산으로 데이터 값 각각에 연산 가능\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### DataFrame 데이터 삭제\n",
    "\n",
    "- df.drop(label, axis, inplace)\n",
    "    - label: 삭제할 인덱스 또는 칼럼의 값\n",
    "    - axis: 대상이 행인지 열인지\n",
    "    - inplace: true 면 원본 데이터프레임이 변형됨(default: false)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Index 객체\n",
    "\n",
    "- RangeIndex \n",
    "- [] 로 접근, 슬라이싱 가능 (한번 만들어진 dataframe 의 인덱스는 readonly)\n",
    "- df 또는 series 에서 reset_index() 수행하면 인덱스 0 부터 1씩 증가하는 수열로 다시 만들고 기존 인덱스는 칼럼명 index 로 칼럼에 추가함\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 데이터 셀렉션 및 필터링\n",
    "\n",
    "- DataFrame[] 은 칼럼 지정하는 용으로 일단 생각\n",
    "- ix\\[row, col\\] 으로 데이터 추출 가능 (deprecated), loc 과 iloc 으로 세분화 되었음\n",
    "    -loc[] - 칼럼 이름 으로 접근\n",
    "    -iloc[] - 칼럼 위치(index) 로 접근\n",
    "- 데이터프레임의 인덱스가 Integer 이면 ix[] 에서 행에 접근시 값으로 접근함\n",
    "- 데이터프레임의 인덱스값은 명칭 기반 인덱싱으로 간주 (ix 는 혼용해서 헷갈리니까 loc, iloc 을 쓰자)\n",
    "- loc 슬라이싱 은 스톱 포함, iloc 은 스탑 -1 까지\n",
    "- 데이터 프레임도 [] 안에 조건식으로  조건식을 만족하는 데이터 프레임 추출 가능\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 정렬, Aggregation 함수, GroupBy 적용\n",
    "\n",
    "- sort_values() - 파라미터 칼럼 으로 정렬\n",
    "- aggregation functions - dataframe 의 모든 칼럼에 적용\n",
    "- groupby() - 파라미터 칼럼 값들로 groupby (반환 객체 : DataFrameGroupBy)\n",
    "    - 리턴 객체에 agg() 적용 가능 (sql 에서의 max, mean, sum ...)\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### 결손 데이터 처리하기\n",
    "\n",
    "- nan 은 머신러닝 알고리즘에서 처리되지 않으므로 다른 값으로 대체해줘야 함\n",
    "    - isna() 로 nan 찾기가능\n",
    "    - fillna() 로 다른 값으로 채우기 가능\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### apply lambda 식으로 데이터 가공\n",
    "\n",
    "- 람다식으로 데이터 처리가능\n",
    "    - if, else 만 지원 (리턴 값 순서에 유의)\n",
    "- 람다식으로 else if 를 사용 할 수 없으므로 경우의 수가 많은 경우 별도의 함수를 만드는 게 낫다\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}