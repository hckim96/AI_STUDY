{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.2 64-bit ('dataStudy': conda)",
   "display_name": "Python 3.8.2 64-bit ('dataStudy': conda)",
   "metadata": {
    "interpreter": {
     "hash": "a22da94b6d0eb1bb9e13ff23c6dec5d5d0682dd7591db237e737d29eb0bbf2ae"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "## 08. 분류 실습 - 캐글 산탄데르 고객 만족 예측\n",
    "\n",
    "- 레이블 명 TARGET, 1: 불만, 0: 만족\n",
    "- 1이 많은 불균일 데이터 라서 accuracy score 보다는 roc-auc 가 평가 성능 지표로 적절"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "dataset shape:  (76020, 371)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   ID  var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0   1     2     23                 0.0                      0.0   \n",
       "1   3     2     34                 0.0                      0.0   \n",
       "2   4     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "0                      0.0                      0.0  ...   \n",
       "1                      0.0                      0.0  ...   \n",
       "2                      0.0                      0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 371 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>var3</th>\n      <th>var15</th>\n      <th>imp_ent_var16_ult1</th>\n      <th>imp_op_var39_comer_ult1</th>\n      <th>imp_op_var39_comer_ult3</th>\n      <th>imp_op_var40_comer_ult1</th>\n      <th>imp_op_var40_comer_ult3</th>\n      <th>imp_op_var40_efect_ult1</th>\n      <th>imp_op_var40_efect_ult3</th>\n      <th>...</th>\n      <th>saldo_medio_var33_hace2</th>\n      <th>saldo_medio_var33_hace3</th>\n      <th>saldo_medio_var33_ult1</th>\n      <th>saldo_medio_var33_ult3</th>\n      <th>saldo_medio_var44_hace2</th>\n      <th>saldo_medio_var44_hace3</th>\n      <th>saldo_medio_var44_ult1</th>\n      <th>saldo_medio_var44_ult3</th>\n      <th>var38</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>2</td>\n      <td>23</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39205.17</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3</td>\n      <td>2</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>49278.03</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>4</td>\n      <td>2</td>\n      <td>23</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>67333.77</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 371 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "\n",
    "cust_df = pd.read_csv(\"data/train.csv\", encoding = \"latin-1\")\n",
    "print(\"dataset shape: \", cust_df.shape)\n",
    "cust_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\nRangeIndex: 76020 entries, 0 to 76019\nColumns: 371 entries, ID to TARGET\ndtypes: float64(111), int64(260)\nmemory usage: 215.2 MB\n"
     ]
    }
   ],
   "source": [
    "cust_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0    73012\n1     3008\nName: TARGET, dtype: int64\nunsatisfied / total =  0.0395685345961589\n"
     ]
    }
   ],
   "source": [
    "print(cust_df[\"TARGET\"].value_counts())\n",
    "unsatisfied_cnt = cust_df[cust_df[\"TARGET\"] == 1].TARGET.count()\n",
    "total_cnt = cust_df.TARGET.count()\n",
    "print(\"unsatisfied / total = \", unsatisfied_cnt / total_cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                  ID           var3         var15  imp_ent_var16_ult1  \\\n",
       "count   76020.000000   76020.000000  76020.000000        76020.000000   \n",
       "mean    75964.050723   -1523.199277     33.212865           86.208265   \n",
       "std     43781.947379   39033.462364     12.956486         1614.757313   \n",
       "min         1.000000 -999999.000000      5.000000            0.000000   \n",
       "25%     38104.750000       2.000000     23.000000            0.000000   \n",
       "50%     76043.000000       2.000000     28.000000            0.000000   \n",
       "75%    113748.750000       2.000000     40.000000            0.000000   \n",
       "max    151838.000000     238.000000    105.000000       210000.000000   \n",
       "\n",
       "       imp_op_var39_comer_ult1  imp_op_var39_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 72.363067               119.529632   \n",
       "std                 339.315831               546.266294   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               12888.030000             21024.810000   \n",
       "\n",
       "       imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  3.559130                 6.472698   \n",
       "std                  93.155749               153.737066   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max                8237.820000             11073.570000   \n",
       "\n",
       "       imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  ...  \\\n",
       "count             76020.000000             76020.000000  ...   \n",
       "mean                  0.412946                 0.567352  ...   \n",
       "std                  30.604864                36.513513  ...   \n",
       "min                   0.000000                 0.000000  ...   \n",
       "25%                   0.000000                 0.000000  ...   \n",
       "50%                   0.000000                 0.000000  ...   \n",
       "75%                   0.000000                 0.000000  ...   \n",
       "max                6600.000000              6600.000000  ...   \n",
       "\n",
       "       saldo_medio_var33_hace2  saldo_medio_var33_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                  7.935824                 1.365146   \n",
       "std                 455.887218               113.959637   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max               50003.880000             20385.720000   \n",
       "\n",
       "       saldo_medio_var33_ult1  saldo_medio_var33_ult3  \\\n",
       "count            76020.000000            76020.000000   \n",
       "mean                12.215580                8.784074   \n",
       "std                783.207399              538.439211   \n",
       "min                  0.000000                0.000000   \n",
       "25%                  0.000000                0.000000   \n",
       "50%                  0.000000                0.000000   \n",
       "75%                  0.000000                0.000000   \n",
       "max             138831.630000            91778.730000   \n",
       "\n",
       "       saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "count             76020.000000             76020.000000   \n",
       "mean                 31.505324                 1.858575   \n",
       "std                2013.125393               147.786584   \n",
       "min                   0.000000                 0.000000   \n",
       "25%                   0.000000                 0.000000   \n",
       "50%                   0.000000                 0.000000   \n",
       "75%                   0.000000                 0.000000   \n",
       "max              438329.220000             24650.010000   \n",
       "\n",
       "       saldo_medio_var44_ult1  saldo_medio_var44_ult3         var38  \\\n",
       "count            76020.000000            76020.000000  7.602000e+04   \n",
       "mean                76.026165               56.614351  1.172358e+05   \n",
       "std               4040.337842             2852.579397  1.826646e+05   \n",
       "min                  0.000000                0.000000  5.163750e+03   \n",
       "25%                  0.000000                0.000000  6.787061e+04   \n",
       "50%                  0.000000                0.000000  1.064092e+05   \n",
       "75%                  0.000000                0.000000  1.187563e+05   \n",
       "max             681462.900000           397884.300000  2.203474e+07   \n",
       "\n",
       "             TARGET  \n",
       "count  76020.000000  \n",
       "mean       0.039569  \n",
       "std        0.194945  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.000000  \n",
       "75%        0.000000  \n",
       "max        1.000000  \n",
       "\n",
       "[8 rows x 371 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>var3</th>\n      <th>var15</th>\n      <th>imp_ent_var16_ult1</th>\n      <th>imp_op_var39_comer_ult1</th>\n      <th>imp_op_var39_comer_ult3</th>\n      <th>imp_op_var40_comer_ult1</th>\n      <th>imp_op_var40_comer_ult3</th>\n      <th>imp_op_var40_efect_ult1</th>\n      <th>imp_op_var40_efect_ult3</th>\n      <th>...</th>\n      <th>saldo_medio_var33_hace2</th>\n      <th>saldo_medio_var33_hace3</th>\n      <th>saldo_medio_var33_ult1</th>\n      <th>saldo_medio_var33_ult3</th>\n      <th>saldo_medio_var44_hace2</th>\n      <th>saldo_medio_var44_hace3</th>\n      <th>saldo_medio_var44_ult1</th>\n      <th>saldo_medio_var44_ult3</th>\n      <th>var38</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>...</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>76020.000000</td>\n      <td>7.602000e+04</td>\n      <td>76020.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>75964.050723</td>\n      <td>-1523.199277</td>\n      <td>33.212865</td>\n      <td>86.208265</td>\n      <td>72.363067</td>\n      <td>119.529632</td>\n      <td>3.559130</td>\n      <td>6.472698</td>\n      <td>0.412946</td>\n      <td>0.567352</td>\n      <td>...</td>\n      <td>7.935824</td>\n      <td>1.365146</td>\n      <td>12.215580</td>\n      <td>8.784074</td>\n      <td>31.505324</td>\n      <td>1.858575</td>\n      <td>76.026165</td>\n      <td>56.614351</td>\n      <td>1.172358e+05</td>\n      <td>0.039569</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>43781.947379</td>\n      <td>39033.462364</td>\n      <td>12.956486</td>\n      <td>1614.757313</td>\n      <td>339.315831</td>\n      <td>546.266294</td>\n      <td>93.155749</td>\n      <td>153.737066</td>\n      <td>30.604864</td>\n      <td>36.513513</td>\n      <td>...</td>\n      <td>455.887218</td>\n      <td>113.959637</td>\n      <td>783.207399</td>\n      <td>538.439211</td>\n      <td>2013.125393</td>\n      <td>147.786584</td>\n      <td>4040.337842</td>\n      <td>2852.579397</td>\n      <td>1.826646e+05</td>\n      <td>0.194945</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>-999999.000000</td>\n      <td>5.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>5.163750e+03</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>38104.750000</td>\n      <td>2.000000</td>\n      <td>23.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>6.787061e+04</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>76043.000000</td>\n      <td>2.000000</td>\n      <td>28.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.064092e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>113748.750000</td>\n      <td>2.000000</td>\n      <td>40.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>1.187563e+05</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>151838.000000</td>\n      <td>238.000000</td>\n      <td>105.000000</td>\n      <td>210000.000000</td>\n      <td>12888.030000</td>\n      <td>21024.810000</td>\n      <td>8237.820000</td>\n      <td>11073.570000</td>\n      <td>6600.000000</td>\n      <td>6600.000000</td>\n      <td>...</td>\n      <td>50003.880000</td>\n      <td>20385.720000</td>\n      <td>138831.630000</td>\n      <td>91778.730000</td>\n      <td>438329.220000</td>\n      <td>24650.010000</td>\n      <td>681462.900000</td>\n      <td>397884.300000</td>\n      <td>2.203474e+07</td>\n      <td>1.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>8 rows × 371 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 4
    }
   ],
   "source": [
    "cust_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cust_df[\"var3\"].value_counts()[:10]\n  2         74165\n 8           138\n-999999      116\n 9           110\n 3           108\n 1           105\n 13           98\n 7            97\n 4            86\n 12           85\nName: var3, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"cust_df[\\\"var3\\\"].value_counts()[:10]\\n\", cust_df[\"var3\"].value_counts()[:10])\n",
    "# -999999 특정 예외 값을 나타내는데 편차가 심해서 가장 값이 많은 2로 바꾸자\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "cust_df[\"var3\"].value_counts()[:10]\n 2     74281\n8       138\n9       110\n3       108\n1       105\n13       98\n7        97\n4        86\n12       85\n6        82\nName: var3, dtype: int64\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   var3  var15  imp_ent_var16_ult1  imp_op_var39_comer_ult1  \\\n",
       "0     2     23                 0.0                      0.0   \n",
       "1     2     34                 0.0                      0.0   \n",
       "2     2     23                 0.0                      0.0   \n",
       "\n",
       "   imp_op_var39_comer_ult3  imp_op_var40_comer_ult1  imp_op_var40_comer_ult3  \\\n",
       "0                      0.0                      0.0                      0.0   \n",
       "1                      0.0                      0.0                      0.0   \n",
       "2                      0.0                      0.0                      0.0   \n",
       "\n",
       "   imp_op_var40_efect_ult1  imp_op_var40_efect_ult3  imp_op_var40_ult1  ...  \\\n",
       "0                      0.0                      0.0                0.0  ...   \n",
       "1                      0.0                      0.0                0.0  ...   \n",
       "2                      0.0                      0.0                0.0  ...   \n",
       "\n",
       "   saldo_medio_var33_hace2  saldo_medio_var33_hace3  saldo_medio_var33_ult1  \\\n",
       "0                      0.0                      0.0                     0.0   \n",
       "1                      0.0                      0.0                     0.0   \n",
       "2                      0.0                      0.0                     0.0   \n",
       "\n",
       "   saldo_medio_var33_ult3  saldo_medio_var44_hace2  saldo_medio_var44_hace3  \\\n",
       "0                     0.0                      0.0                      0.0   \n",
       "1                     0.0                      0.0                      0.0   \n",
       "2                     0.0                      0.0                      0.0   \n",
       "\n",
       "   saldo_medio_var44_ult1  saldo_medio_var44_ult3     var38  TARGET  \n",
       "0                     0.0                     0.0  39205.17       0  \n",
       "1                     0.0                     0.0  49278.03       0  \n",
       "2                     0.0                     0.0  67333.77       0  \n",
       "\n",
       "[3 rows x 370 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>var3</th>\n      <th>var15</th>\n      <th>imp_ent_var16_ult1</th>\n      <th>imp_op_var39_comer_ult1</th>\n      <th>imp_op_var39_comer_ult3</th>\n      <th>imp_op_var40_comer_ult1</th>\n      <th>imp_op_var40_comer_ult3</th>\n      <th>imp_op_var40_efect_ult1</th>\n      <th>imp_op_var40_efect_ult3</th>\n      <th>imp_op_var40_ult1</th>\n      <th>...</th>\n      <th>saldo_medio_var33_hace2</th>\n      <th>saldo_medio_var33_hace3</th>\n      <th>saldo_medio_var33_ult1</th>\n      <th>saldo_medio_var33_ult3</th>\n      <th>saldo_medio_var44_hace2</th>\n      <th>saldo_medio_var44_hace3</th>\n      <th>saldo_medio_var44_ult1</th>\n      <th>saldo_medio_var44_ult3</th>\n      <th>var38</th>\n      <th>TARGET</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2</td>\n      <td>23</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>39205.17</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>34</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>49278.03</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>23</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>67333.77</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>3 rows × 370 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "cust_df[\"var3\"].replace(-999999, 2, inplace = True)\n",
    "cust_df.drop(\"ID\", axis = 1, inplace = True)\n",
    "\n",
    "print(\"cust_df[\\\"var3\\\"].value_counts()[:10]\\n\", cust_df[\"var3\"].value_counts()[:10])\n",
    "cust_df.head(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "train: (60816, 369), test: (15204, 369)\n60816\ntrain\n 0    0.960964\n1    0.039036\nName: TARGET, dtype: float64\ntest\n 0    0.9583\n1    0.0417\nName: TARGET, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_features = cust_df.iloc[:, :-1]\n",
    "y_labels = cust_df.iloc[:, -1]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_features, y_labels, test_size = 0.2, random_state = 0)\n",
    "\n",
    "print(f\"train: {X_train.shape}, test: {X_test.shape}\")\n",
    "print(y_train.count())\n",
    "\n",
    "print(f\"train\\n {y_train.value_counts()/ y_train.count()}\")\n",
    "print(f\"test\\n {y_test.value_counts()/ y_test.count()}\")\n",
    "# 학습, 테스트 데이터 라벨 비율이 비슷하게 만들어짐\n"
   ]
  },
  {
   "source": [
    "### XGBoost 모델 학습과 하이퍼 파라미터 튜닝\n",
    "\n",
    "- 평가 데이터 세트로 테스트 데이터 세트 사용하면 과적합 가능성 증가함\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0]\tvalidation_0-auc:0.82005\tvalidation_1-auc:0.81157\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 50 rounds.\n",
      "[15]\tvalidation_0-auc:0.88072\tvalidation_1-auc:0.84117\n",
      "[30]\tvalidation_0-auc:0.89738\tvalidation_1-auc:0.83959\n",
      "[45]\tvalidation_0-auc:0.90767\tvalidation_1-auc:0.83693\n",
      "[60]\tvalidation_0-auc:0.91762\tvalidation_1-auc:0.83576\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-auc:0.87799\tvalidation_1-auc:0.84135\n",
      "\n",
      "ROC AUC: 0.8413487915404584\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators = 250, random_state = 156)\n",
    "\n",
    "xgb_clf.fit(X_train, y_train, early_stopping_rounds = 50, eval_metric = \"auc\", eval_set = [(X_train, y_train), (X_test, y_test)], verbose = 15)\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, xgb_clf.predict_proba(X_test)[:, 1], average = \"macro\")\n",
    "print(f\"ROC AUC: {xgb_roc_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[0]\tvalidation_0-auc:0.71214\tvalidation_1-auc:0.71487\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.85352\tvalidation_1-auc:0.83359\n",
      "[30]\tvalidation_0-auc:0.86454\tvalidation_1-auc:0.83584\n",
      "[45]\tvalidation_0-auc:0.86860\tvalidation_1-auc:0.83482\n",
      "[49]\tvalidation_0-auc:0.86984\tvalidation_1-auc:0.83489\n",
      "[0]\tvalidation_0-auc:0.69509\tvalidation_1-auc:0.69896\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.85501\tvalidation_1-auc:0.83771\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-auc:0.85000\tvalidation_1-auc:0.84021\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71220\tvalidation_1-auc:0.71486\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.85163\tvalidation_1-auc:0.83764\n",
      "[30]\tvalidation_0-auc:0.86212\tvalidation_1-auc:0.83486\n",
      "Stopping. Best iteration:\n",
      "[18]\tvalidation_0-auc:0.85605\tvalidation_1-auc:0.83886\n",
      "\n",
      "[0]\tvalidation_0-auc:0.69771\tvalidation_1-auc:0.70562\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.85140\tvalidation_1-auc:0.83953\n",
      "[30]\tvalidation_0-auc:0.86129\tvalidation_1-auc:0.83977\n",
      "Stopping. Best iteration:\n",
      "[25]\tvalidation_0-auc:0.85835\tvalidation_1-auc:0.84137\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71242\tvalidation_1-auc:0.70830\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.86681\tvalidation_1-auc:0.83090\n",
      "Stopping. Best iteration:\n",
      "[12]\tvalidation_0-auc:0.86265\tvalidation_1-auc:0.83221\n",
      "\n",
      "[0]\tvalidation_0-auc:0.69998\tvalidation_1-auc:0.70335\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.86724\tvalidation_1-auc:0.83644\n",
      "[30]\tvalidation_0-auc:0.88042\tvalidation_1-auc:0.83768\n",
      "Stopping. Best iteration:\n",
      "[21]\tvalidation_0-auc:0.87493\tvalidation_1-auc:0.83983\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71523\tvalidation_1-auc:0.71608\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.86250\tvalidation_1-auc:0.83184\n",
      "Stopping. Best iteration:\n",
      "[7]\tvalidation_0-auc:0.84689\tvalidation_1-auc:0.83506\n",
      "\n",
      "[0]\tvalidation_0-auc:0.69819\tvalidation_1-auc:0.70556\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.86250\tvalidation_1-auc:0.83959\n",
      "[30]\tvalidation_0-auc:0.87370\tvalidation_1-auc:0.83807\n",
      "Stopping. Best iteration:\n",
      "[22]\tvalidation_0-auc:0.86830\tvalidation_1-auc:0.84188\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70802\tvalidation_1-auc:0.71197\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.85520\tvalidation_1-auc:0.83796\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-auc:0.85394\tvalidation_1-auc:0.83830\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70190\tvalidation_1-auc:0.70489\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.85724\tvalidation_1-auc:0.83858\n",
      "Stopping. Best iteration:\n",
      "[14]\tvalidation_0-auc:0.85566\tvalidation_1-auc:0.83921\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71008\tvalidation_1-auc:0.71903\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.85435\tvalidation_1-auc:0.83582\n",
      "[30]\tvalidation_0-auc:0.86325\tvalidation_1-auc:0.83235\n",
      "Stopping. Best iteration:\n",
      "[15]\tvalidation_0-auc:0.85435\tvalidation_1-auc:0.83582\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70654\tvalidation_1-auc:0.71152\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.85589\tvalidation_1-auc:0.83909\n",
      "[30]\tvalidation_0-auc:0.86461\tvalidation_1-auc:0.83994\n",
      "Stopping. Best iteration:\n",
      "[24]\tvalidation_0-auc:0.86114\tvalidation_1-auc:0.84070\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71272\tvalidation_1-auc:0.71873\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.87108\tvalidation_1-auc:0.83214\n",
      "Stopping. Best iteration:\n",
      "[5]\tvalidation_0-auc:0.84524\tvalidation_1-auc:0.83534\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70656\tvalidation_1-auc:0.70939\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.87197\tvalidation_1-auc:0.83827\n",
      "[30]\tvalidation_0-auc:0.88278\tvalidation_1-auc:0.83645\n",
      "Stopping. Best iteration:\n",
      "[26]\tvalidation_0-auc:0.87974\tvalidation_1-auc:0.83961\n",
      "\n",
      "[0]\tvalidation_0-auc:0.71064\tvalidation_1-auc:0.71919\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.86672\tvalidation_1-auc:0.83209\n",
      "Stopping. Best iteration:\n",
      "[7]\tvalidation_0-auc:0.85216\tvalidation_1-auc:0.83669\n",
      "\n",
      "[0]\tvalidation_0-auc:0.70842\tvalidation_1-auc:0.71271\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.86462\tvalidation_1-auc:0.84038\n",
      "[30]\tvalidation_0-auc:0.87513\tvalidation_1-auc:0.83729\n",
      "Stopping. Best iteration:\n",
      "[16]\tvalidation_0-auc:0.86569\tvalidation_1-auc:0.84084\n",
      "\n",
      "[0]\tvalidation_0-auc:0.73593\tvalidation_1-auc:0.74368\n",
      "Multiple eval metrics have been passed: 'validation_1-auc' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-auc hasn't improved in 15 rounds.\n",
      "[15]\tvalidation_0-auc:0.86689\tvalidation_1-auc:0.84319\n",
      "[30]\tvalidation_0-auc:0.88259\tvalidation_1-auc:0.84070\n",
      "Stopping. Best iteration:\n",
      "[15]\tvalidation_0-auc:0.86689\tvalidation_1-auc:0.84319\n",
      "\n",
      "best parmas:  {'colsample_bytree': 0.75, 'max_depth': 5, 'min_child_weight': 1}\n",
      "ROC AUC:  0.8431858384087263\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "xgb_clf = XGBClassifier(n_estimators = 50)\n",
    "params = {\n",
    "    \"max_depth\": [5, 7],\n",
    "    \"min_child_weight\":[1, 3],\n",
    "    \"colsample_bytree\":[0.5, 0.75]\n",
    "}\n",
    "\n",
    "gridcv = GridSearchCV(xgb_clf, param_grid = params, cv = 2)\n",
    "gridcv.fit(X_train, y_train, early_stopping_rounds = 15, eval_metric= \"auc\", eval_set = [(X_train, y_train), (X_test, y_test)], verbose = 15)\n",
    "\n",
    "print(\"best parmas: \", gridcv.best_params_)\n",
    "xgb_roc_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:, 1], average = \"macro\")\n",
    "print(\"ROC AUC: \", xgb_roc_score)\n",
    "\n"
   ]
  },
  {
   "source": [
    "- GridSearchCV 로 구한 최적 파라미터와 다른 파라미터를 추가해서 더 많은 파라미터를 최적화 시킬 수 있다.\n",
    "- fit한 classifier 를 plot importance() 로 피처 중요도 시각화 가능\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### LightGBM 모델 학습과 하이퍼 파라미터 튜닝\n",
    "\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[15]\tvalid_0's auc: 0.840928\tvalid_0's binary_logloss: 0.14161\n",
      "[30]\tvalid_0's auc: 0.839196\tvalid_0's binary_logloss: 0.139641\n",
      "[45]\tvalid_0's auc: 0.839703\tvalid_0's binary_logloss: 0.139445\n",
      "[60]\tvalid_0's auc: 0.838319\tvalid_0's binary_logloss: 0.13969\n",
      "[75]\tvalid_0's auc: 0.83772\tvalid_0's binary_logloss: 0.13992\n",
      "[90]\tvalid_0's auc: 0.836752\tvalid_0's binary_logloss: 0.140225\n",
      "[105]\tvalid_0's auc: 0.836752\tvalid_0's binary_logloss: 0.140391\n",
      "Early stopping, best iteration is:\n",
      "[15]\tvalid_0's auc: 0.840928\tvalid_0's binary_logloss: 0.14161\n",
      "ROC AUC:  0.8409281094855902\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 500)\n",
    "evals = [(X_test, y_test)]\n",
    "\n",
    "lgbm_clf.fit(X_train, y_train, early_stopping_rounds = 100, eval_metric = \"auc\", eval_set = evals, verbose = 15)\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1], average = \"macro\")\n",
    "print(\"ROC AUC: \", lgbm_roc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.845435\tvalid_0's binary_logloss: 0.137252\tvalid_1's auc: 0.836312\tvalid_1's binary_logloss: 0.147155\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[30]\tvalid_0's auc: 0.86812\tvalid_0's binary_logloss: 0.125364\tvalid_1's auc: 0.836871\tvalid_1's binary_logloss: 0.139878\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.864708\tvalid_0's binary_logloss: 0.126629\tvalid_1's auc: 0.837921\tvalid_1's binary_logloss: 0.140053\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.845435\tvalid_0's binary_logloss: 0.137252\tvalid_1's auc: 0.836312\tvalid_1's binary_logloss: 0.147155\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[30]\tvalid_0's auc: 0.86812\tvalid_0's binary_logloss: 0.125364\tvalid_1's auc: 0.836871\tvalid_1's binary_logloss: 0.139878\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.864708\tvalid_0's binary_logloss: 0.126629\tvalid_1's auc: 0.837921\tvalid_1's binary_logloss: 0.140053\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.857254\tvalid_0's binary_logloss: 0.133887\tvalid_1's auc: 0.830156\tvalid_1's binary_logloss: 0.146858\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.862299\tvalid_0's binary_logloss: 0.130787\tvalid_1's auc: 0.837073\tvalid_1's binary_logloss: 0.143793\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.857254\tvalid_0's binary_logloss: 0.133887\tvalid_1's auc: 0.830156\tvalid_1's binary_logloss: 0.146858\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.862299\tvalid_0's binary_logloss: 0.130787\tvalid_1's auc: 0.837073\tvalid_1's binary_logloss: 0.143793\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.847152\tvalid_0's binary_logloss: 0.136429\tvalid_1's auc: 0.834666\tvalid_1's binary_logloss: 0.146638\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[30]\tvalid_0's auc: 0.865924\tvalid_0's binary_logloss: 0.126268\tvalid_1's auc: 0.839278\tvalid_1's binary_logloss: 0.139331\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.861323\tvalid_0's binary_logloss: 0.12813\tvalid_1's auc: 0.839703\tvalid_1's binary_logloss: 0.139807\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.847152\tvalid_0's binary_logloss: 0.136429\tvalid_1's auc: 0.834666\tvalid_1's binary_logloss: 0.146638\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[30]\tvalid_0's auc: 0.865924\tvalid_0's binary_logloss: 0.126268\tvalid_1's auc: 0.839278\tvalid_1's binary_logloss: 0.139331\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.861323\tvalid_0's binary_logloss: 0.12813\tvalid_1's auc: 0.839703\tvalid_1's binary_logloss: 0.139807\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.861986\tvalid_0's binary_logloss: 0.129969\tvalid_1's auc: 0.825386\tvalid_1's binary_logloss: 0.144336\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.856353\tvalid_0's binary_logloss: 0.135676\tvalid_1's auc: 0.836837\tvalid_1's binary_logloss: 0.145933\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.861986\tvalid_0's binary_logloss: 0.129969\tvalid_1's auc: 0.825386\tvalid_1's binary_logloss: 0.144336\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.856353\tvalid_0's binary_logloss: 0.135676\tvalid_1's auc: 0.836837\tvalid_1's binary_logloss: 0.145933\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.845435\tvalid_0's binary_logloss: 0.137252\tvalid_1's auc: 0.836312\tvalid_1's binary_logloss: 0.147155\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[30]\tvalid_0's auc: 0.86812\tvalid_0's binary_logloss: 0.125364\tvalid_1's auc: 0.836871\tvalid_1's binary_logloss: 0.139878\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.864708\tvalid_0's binary_logloss: 0.126629\tvalid_1's auc: 0.837921\tvalid_1's binary_logloss: 0.140053\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.845435\tvalid_0's binary_logloss: 0.137252\tvalid_1's auc: 0.836312\tvalid_1's binary_logloss: 0.147155\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[30]\tvalid_0's auc: 0.86812\tvalid_0's binary_logloss: 0.125364\tvalid_1's auc: 0.836871\tvalid_1's binary_logloss: 0.139878\n",
      "Early stopping, best iteration is:\n",
      "[25]\tvalid_0's auc: 0.864708\tvalid_0's binary_logloss: 0.126629\tvalid_1's auc: 0.837921\tvalid_1's binary_logloss: 0.140053\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.857254\tvalid_0's binary_logloss: 0.133887\tvalid_1's auc: 0.830156\tvalid_1's binary_logloss: 0.146858\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.862299\tvalid_0's binary_logloss: 0.130787\tvalid_1's auc: 0.837073\tvalid_1's binary_logloss: 0.143793\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.857254\tvalid_0's binary_logloss: 0.133887\tvalid_1's auc: 0.830156\tvalid_1's binary_logloss: 0.146858\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.862299\tvalid_0's binary_logloss: 0.130787\tvalid_1's auc: 0.837073\tvalid_1's binary_logloss: 0.143793\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.847152\tvalid_0's binary_logloss: 0.136429\tvalid_1's auc: 0.834666\tvalid_1's binary_logloss: 0.146638\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[30]\tvalid_0's auc: 0.865924\tvalid_0's binary_logloss: 0.126268\tvalid_1's auc: 0.839278\tvalid_1's binary_logloss: 0.139331\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.861323\tvalid_0's binary_logloss: 0.12813\tvalid_1's auc: 0.839703\tvalid_1's binary_logloss: 0.139807\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[9]\tvalid_0's auc: 0.847152\tvalid_0's binary_logloss: 0.136429\tvalid_1's auc: 0.834666\tvalid_1's binary_logloss: 0.146638\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "[30]\tvalid_0's auc: 0.865924\tvalid_0's binary_logloss: 0.126268\tvalid_1's auc: 0.839278\tvalid_1's binary_logloss: 0.139331\n",
      "Early stopping, best iteration is:\n",
      "[23]\tvalid_0's auc: 0.861323\tvalid_0's binary_logloss: 0.12813\tvalid_1's auc: 0.839703\tvalid_1's binary_logloss: 0.139807\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.861986\tvalid_0's binary_logloss: 0.129969\tvalid_1's auc: 0.825386\tvalid_1's binary_logloss: 0.144336\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.856353\tvalid_0's binary_logloss: 0.135676\tvalid_1's auc: 0.836837\tvalid_1's binary_logloss: 0.145933\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[14]\tvalid_0's auc: 0.861986\tvalid_0's binary_logloss: 0.129969\tvalid_1's auc: 0.825386\tvalid_1's binary_logloss: 0.144336\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[8]\tvalid_0's auc: 0.856353\tvalid_0's binary_logloss: 0.135676\tvalid_1's auc: 0.836837\tvalid_1's binary_logloss: 0.145933\n",
      "Training until validation scores don't improve for 15 rounds\n",
      "Early stopping, best iteration is:\n",
      "[13]\ttraining's auc: 0.877607\ttraining's binary_logloss: 0.126517\tvalid_1's auc: 0.840082\tvalid_1's binary_logloss: 0.142121\n",
      "best parmas:  {'max_depth': 128, 'min_child_samples': 60, 'num_leaves': 64, 'subsample': 0.8}\n",
      "ROC AUC:  0.8400817114809612\n"
     ]
    }
   ],
   "source": [
    "# 하이퍼 파라미터 튜닝\n",
    "\n",
    "lgbm_clf = LGBMClassifier(n_estimators = 100)\n",
    "params = {\n",
    "    \"num_leaves\": [32, 64],\n",
    "    \"max_depth\": [128, 160],\n",
    "    \"min_child_samples\": [60, 100],\n",
    "    \"subsample\": [0.8, 1]\n",
    "}\n",
    "gridcv = GridSearchCV(lgbm_clf, param_grid = params, cv = 2)\n",
    "gridcv.fit(X_train, y_train, early_stopping_rounds = 15, eval_metric = \"auc\", eval_set = [(X_train, y_train), (X_test, y_test)], verbose = 30)\n",
    "\n",
    "print(\"best parmas: \", gridcv.best_params_)\n",
    "lgbm_roc_score = roc_auc_score(y_test, gridcv.predict_proba(X_test)[:, 1], average = \"macro\")\n",
    "print(\"ROC AUC: \", lgbm_roc_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[15]\tvalid_0's auc: 0.84154\tvalid_0's binary_logloss: 0.141254\n",
      "[30]\tvalid_0's auc: 0.838922\tvalid_0's binary_logloss: 0.139324\n",
      "[45]\tvalid_0's auc: 0.838529\tvalid_0's binary_logloss: 0.139115\n",
      "[60]\tvalid_0's auc: 0.838145\tvalid_0's binary_logloss: 0.13923\n",
      "[75]\tvalid_0's auc: 0.837359\tvalid_0's binary_logloss: 0.139475\n",
      "[90]\tvalid_0's auc: 0.836314\tvalid_0's binary_logloss: 0.139907\n",
      "[105]\tvalid_0's auc: 0.834578\tvalid_0's binary_logloss: 0.140374\n",
      "Early stopping, best iteration is:\n",
      "[11]\tvalid_0's auc: 0.841659\tvalid_0's binary_logloss: 0.14327\n",
      "ROC AUC:  0.8416587279076968\n"
     ]
    }
   ],
   "source": [
    "lgbm_clf = LGBMClassifier(n_estimators = 1000, num_leaves = 32, subsample = 0.8, min_child_samples = 100, max_depth = 128)\n",
    "evals = [(X_test, y_test)]\n",
    "lgbm_clf.fit(X_train, y_train, early_stopping_rounds = 100, eval_metric = \"auc\", eval_set = evals, verbose = 15)\n",
    "lgbm_roc_score = roc_auc_score(y_test, lgbm_clf.predict_proba(X_test)[:, 1], average = \"macro\")\n",
    "\n",
    "print(\"ROC AUC: \", lgbm_roc_score)\n"
   ]
  }
 ]
}